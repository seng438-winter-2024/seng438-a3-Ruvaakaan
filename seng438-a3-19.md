**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 â€“ Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      |    19    |
| -------------- | -------- |
| Student Names: |          |
| Andrew Duong   | 30139573 |
| Ethan Bensler  | 30140326 |
| Joseph Duong   | 30145210 |
| Liam Brennan   | 30142832 |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

This assignment aims to familiarize students with the assessment of white-box test suite adequacy through code coverage. White-box testing evaluates test suite effectiveness by the extent of code exercised. Various coverage criteria such as statement, decision, condition, path, and data-flow coverage are explored. By completing the assignment, students will learn to utilize code coverage tools, enhance code coverage through test case design, grasp the advantages and limitations of code coverage assessment, and comprehend data-flow coverage principles, including manual calculation techniques.

# 2 Manual data-flow coverage calculations for X and Y methods

Below is the Data Flow Diagram for the getUpperBound method of the Range class:

![RangeDFG-SENG-401 drawio](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/95046408/26f1ddd7-a6e5-494b-8f8e-3b44bd014353)

def-use sets per statement:

|   statement    |    definition    |    use    |
| -------------- | -------- | -------- |
| public double getLowerBound() | lower, upper | none |
| if (lower > upper)   | none | lower, upper |
| String msg = "Range(double, double): require lower (" + lower+ ") <= upper (" + upper + ")." | msg | lower, upper |
| return this.lower | none | lower |

du-pairs per variable:

|   variable   |    du-pairs    |
| -------------- | -------- | 
| lower | (1,1), (1,2), (1,3) |
| upper   | (1,1), (1,3) |
| msg | (3,3) |

du-pairs covered per test-case:

|   test-case   |      lower | upper | msg | 
| -------------- | -------- | ---- | ----- |
| testLowerBoundJustBelowMaximum() | (1,2), (1,1) | (1,1) | none | 
| testLowerBoundAtMinimum()   | (1,2), (1,1) | (1,1) | none | 
| testInvalidLowerBoundNaN() | (1,2), (1,1) | (1,1) | none | 
| testLowerBoundJustAboveMinimum() | (1,2), (1,1) | (1,1) | none | 
| testValidLowerBound() | (1,2), (1,1) | (1,1) | none | 

du-pair coverage:

|   total number of unique du-pairs   |      number of covered du-pairs |du-pair coverage | 
| -------------- | -------- | ---- | 
| 4 | 2 | ( 2 / 4 ) * 100% = 50% | 

Below is the Data Flow Diagram for the calculateColumnTotal method of the DataUtilities class:

![DFG](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/113311709/a7523d81-f415-43b2-874c-1a865d09bb31)

def-use sets per statement:

![dustatement](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/113311709/01a843a5-3d52-4fc6-b558-81523dfa9b50)

du-pairs per variable:

![duvariable](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/113311709/07add607-bdf5-4a8b-8616-be0a7d2db11e)

du-pairs covered per test-case:

![dutest](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/113311709/a6b5997b-808e-4dec-b632-8dd560fec5bd)

du-pair coverage:

Coverage % = (Number of covered Def-Use pairs / Total number of unique Def-Use pairs) x 100% = 15/15 x 100% = 100%

# 3 A detailed description of the testing strategy for the new unit test

The approach that we took towards the development of the new unit tests was twofold. Firstly, we imported our previous tests made in assignment 2 to this test suite. This would serve as a starting point. Thereafter we aimed at achieving the required 60% metric for condition coverage and the 70% condition for branch coverage. The reason for this approach is that branch and condition coverage subsume statement coverage, and by focusing our efforts on achieving these metrics first, that the 90% requirement for statement coverage would be achieved as a byproduct.

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

1. When testing the expand function in the Range class initially, we observed that not all branches were being taken. Upon further examination of the source code, we realized that the reason for this coverage is that we weren't testing an edge case where an input of 2 negative margins cause the upper bound of the range to be below the lower bound of the range. By observing that this branch wasn't taken, we included test cases to account for that branch and thus increase our code coverage.

2. In the Range class the constructor makes a check to make sure that the lower bound is less than or equal to the upper bound before instantiating the class. This check is also done in other functions in the range class, such as the 'getLength()' method. When testing, we noticed that branch coverage was missing from these branches where this redundant check was made, and were able to connclude that that portion of the code was unreachable and therefore untestable. Therefore we perceived the code coverage to be higher than what the tools said due to these redundancies.

3. In DataUtilites for the getCumulativePercentage method, there was an infinite loop that was unreachable which decreased the branch and statement coverage of our tests. To account for this, we made a test case where the mock KeyedValues object contained a negative length which would allow it to enter the loop. The condition for the loop made it so that as long as a set variable that was set to 0 was greater than the length of the KeyedValues object, then the loop would continue. Since the length we are passing in as negative, the code will loop forever. Consequently, in our test, we set a timeout of 1 second to terminate the test.

4. We also expanded our DataUtitlities tests to cover some of the other methods. Specifically for the equal method, we were able to create additional tests to cover the many branches, thus increasing our branch coverage and consequently, our overall coverage.
   
5. Additionally, as part of our expansion of the DataUtilities tests, we also made tests for the clone method as well. In the previous expansion with equal, we were able to meet the coverage criteria for branch but still lacked in overall line coverage. To suplement this, we created additional tests for clone that covered the last few lines needed for near full coverage. Important to note that after doing so, the only line coverage we were missing in the DataUtilites tests were another infinite loop in the calculateColumnTotal and a piece of code that would never be executed as the source code did not allow it.

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Range Class Before:

![beforeRange](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/95046408/1128cfe1-9725-4918-be25-2d67218c34e5)

DataUtilities Class Before:

![beforeDataUtilities](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/95046408/8e6c7734-a0f8-42f8-8e5c-77f0626bce70)

Range Class After:

![afterRange](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/95046408/dd0a9ac8-8f91-494b-831e-0fb2d872618d)

DataUtilities Class After:

![afterDataUtilities](https://github.com/seng438-winter-2024/seng438-a3-Ruvaakaan/assets/113631518/07e04f97-2fc6-4d79-b999-092183822c8a)

# 6 Pros and Cons of coverage tools used and Metrics you report

We employed two code coverage tools: EclEmma and CodeCover. Initially, we intended to utilize CodeCover specifically for condition coverage analysis. However, CodeCover failed to provide condition coverage. Therefore, we opted to rely solely on EclEmma for reporting line coverage, branch coverage, and method coverage, substituting condition coverage with method coverage. 

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Requirements-based testing is centered on verifying that the project satisfies defined requirements and functions as intended. Although, it runs the risk of neglecting the system's internal structure or implementation specifics, potentially resulting in significant defects remaining undetected within the code. Conversely, coverage-based testing scrutinizes the code at a smaller level, enabling the detection of critical defects embedded within it. However, it may falter in testing system requirements comprehensively. This is why a combined approach, leveraging both techniques, is typically adopted to ensure thorough testing coverage.

# 8 A discussion on how the team work/effort was divided and managed

Similar to the previous project, Andrew and Joseph were responsible for anything related to the DataUtilities class, while Ethan and Liam were assigned tasks related to the Range class. All team members participated in testing the code coverage tools mentioned earlier and we all communicated with one another throughout the project. 

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

We encountered difficulties navigating the usage of the code coverage tools due to the lack of recent documentation for either testing tool. Additionally, locating the source code of the projects proved challenging initially, causing confusion. A significant obstacle arose from the fact that, for the previous assignment, our tests were organized into individual files. However, for this project, we needed to assess the total coverage for two separate classes. Therefore, we had to combine of all our test files into two distinct classes, which consumed considerable time and effort.

# 10 Comments/feedback on the lab itself

The lab provided valuable learning opportunities as outlined in the lab handout. Nonetheless, there is room for improvement, particularly in utilizing more up-to-date Integrated Development Environments (IDEs) and testing tools. Upgrading to newer IDEs and testing tools would enhance our workflow and productivity, ensuring a smoother and more efficient development process.
